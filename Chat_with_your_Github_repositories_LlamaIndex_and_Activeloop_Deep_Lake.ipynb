{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuwqDpFjIbMvVjBa+NDaZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianMutea/Chat-with-your-Github-repositories-LlamaIndex-and-Activeloop-Deep-Lake.ipynb/blob/main/Chat_with_your_Github_repositories_LlamaIndex_and_Activeloop_Deep_Lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with your Github repositories using LlamaIndex\n",
        "\n",
        "You'll learn how to effortlessly index GitHub repositories into Deep Lake and interact with your code through natural language queries."
      ],
      "metadata": {
        "id": "rFX-y3VR3FpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How does LLamaIndex work?\n",
        "In the context of leveraging LlamaIndex for data-driven applications, the underlying logic and workflow are pretty simple. Here's a breakdown:\n",
        "\n",
        "* **Load Documents**: The first step involves loading your raw data into the system. You can do this manually, directly inputting the data, or through a data loader that automates the process. LlamaIndex offers specialized data loaders that can ingest data from various sources, transforming them into Document objects, and you can find many plugins on Llama Hub. This is a crucial step as it sets the stage for the subsequent data manipulation and querying functionalities.\n",
        "* **Parse the Documents into Nodes**: Once the documents are loaded, they are parsed into Nodes, essentially structured data units. These Nodes contain chunks of the original documents and carry valuable metadata and relationship information. This parsing process is vital as it organizes the raw data into a structured format, making it easier and more efficient for the system to handle.\n",
        "* **Construct an Index from Nodes or Documents**: After the Nodes are prepared, an index is constructed to make the data searchable and queryable. Depending on your needs, this index can be built directly from the original documents or the parsed Nodes. The index is often stored in structures like VectorStoreIndex, optimized for quick data retrieval. This step is the system's heart, turning your structured data into a robust, queryable database.\n",
        "* **Query the Index**: With the index in place, the final step is to query it. A query engine is initialized, allowing you to make natural language queries against the indexed data. This is where the magic happens: you can conversationally ask the system questions, and it will sift through the indexed data to provide accurate and relevant answers."
      ],
      "metadata": {
        "id": "vbJ7nxjD6R9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6QSkLOtTg3by"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q llama-index==0.9.14.post3 openai==1.3.8 cohere==4.37 deeplake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = \"your_activeloop_toke\"\n",
        "os.environ[\"GITHUB_TOKEN\"] = \"your_github_classic_token\"\n",
        "\n",
        "dataset_path=f\"hub://{'brianmuteak'}/{'git_repository_vdata'}\""
      ],
      "metadata": {
        "id": "gReOj3H_kweu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch and set API keys\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "github_token = os.getenv(\"GITHUB_TOKEN\")"
      ],
      "metadata": {
        "id": "3B5NWHxfmzNn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install llama_hub"
      ],
      "metadata": {
        "id": "ySzFRdH4nLkf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "from llama_index import download_loader\n",
        "from llama_hub.github_repo import GithubRepositoryReader, GithubClient\n",
        "from llama_index import VectorStoreIndex, GPTVectorStoreIndex\n",
        "\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "import re"
      ],
      "metadata": {
        "id": "XjITWna7nA-k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_github_url(url):\n",
        "  pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
        "  match = re.match(pattern, url)\n",
        "  return match.groups() if match else (None, None)\n",
        "\n",
        "\n",
        "def validate_owner_repo(owner, repo):\n",
        "  return bool(owner) and bool(repo)\n",
        "\n",
        "\n",
        "def initialize_github_client():\n",
        "  github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "  return GithubClient(github_token)\n",
        "\n",
        "\n",
        "def main():\n",
        "  # Check for OpenAI API key\n",
        "  openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  if not openai_api_key:\n",
        "      raise EnvironmentError(\"OpenAI API key not found in environment variables\")\n",
        "\n",
        "  # Check for GitHub Token\n",
        "  github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "  if not github_token:\n",
        "      raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
        "\n",
        "  # Check for Activeloop Token\n",
        "  active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "  if not active_loop_token:\n",
        "      raise EnvironmentError(\"Activeloop token not found in environment variables\")\n",
        "\n",
        "  github_client = initialize_github_client()\n",
        "  download_loader(\"GithubRepositoryReader\")\n",
        "\n",
        "  github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "  owner, repo = parse_github_url(github_url)\n",
        "\n",
        "  while True:\n",
        "      owner, repo = parse_github_url(github_url)\n",
        "      if validate_owner_repo(owner, repo):\n",
        "          loader = GithubRepositoryReader(\n",
        "              github_client,\n",
        "              owner=owner,\n",
        "              repo=repo,\n",
        "              filter_file_extensions=(\n",
        "                  [\".ipynb\"],\n",
        "                  GithubRepositoryReader.FilterType.INCLUDE,\n",
        "              ),\n",
        "              verbose=False,\n",
        "              concurrent_requests=5,\n",
        "          )\n",
        "          print(f\"Loading {repo} repository by {owner}\")\n",
        "          docs = loader.load_data(branch=\"main\")\n",
        "          print(\"Documents uploaded:\")\n",
        "          for doc in docs:\n",
        "              print(doc.metadata)\n",
        "          break  # Exit the loop once the valid URL is processed\n",
        "      else:\n",
        "          print(\"Invalid GitHub URL. Please try again.\")\n",
        "          github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "\n",
        "  print(\"Uploading to vector store...\")\n",
        "\n",
        "  # ====== Create vector store and upload data ======\n",
        "\n",
        "  vector_store = DeepLakeVectorStore(\n",
        "      dataset_path= dataset_path,\n",
        "      overwrite=True,\n",
        "      runtime={\"tensor_db\": True},\n",
        "  )\n",
        "\n",
        "  storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
        "  index = VectorStoreIndex.from_documents(\n",
        "      docs, storage_context = storage_context\n",
        "      )\n",
        "  query_engine = index.as_query_engine()\n",
        "\n",
        "  # Include a simple question to test.\n",
        "  intro_question = \"What is the repository about?\"\n",
        "  print(f\"Test question: {intro_question}\")\n",
        "  print(\"=\" * 50)\n",
        "  answer = query_engine.query(intro_question)\n",
        "\n",
        "  print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "  while True:\n",
        "      user_question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
        "      if user_question.lower() == \"exit\":\n",
        "          print(\"Exiting, thanks for chatting!\")\n",
        "          break\n",
        "\n",
        "      print(f\"Your question: {user_question}\")\n",
        "      print(\"=\" * 50)\n",
        "\n",
        "      answer = query_engine.query(user_question)\n",
        "      print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqGsg1RjnIJQ",
        "outputId": "30b7875b-5228-4d55-b774-e623959bee0e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the GitHub repository URL: https://github.com/brianMutea/LlamaIndex-Precision-and-Simplicity-in-Information-Retrieval\n",
            "Loading LlamaIndex-Precision-and-Simplicity-in-Information-Retrieval repository by brianMutea\n",
            "Documents uploaded:\n",
            "{'file_path': 'LlamaIndex_Introduction_Precision_and_Simplicity_in_Information_Retrieval.ipynb', 'file_name': 'LlamaIndex_Introduction_Precision_and_Simplicity_in_Information_Retrieval.ipynb', 'url': 'https://github.com/brianMutea/LlamaIndex-Precision-and-Simplicity-in-Information-Retrieval/blob/main/LlamaIndex_Introduction_Precision_and_Simplicity_in_Information_Retrieval.ipynb'}\n",
            "Uploading to vector store...\n",
            "Your Deep Lake dataset has been successfully created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading data to deeplake dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 43.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://brianmuteak/git_repository_vdata', tensors=['text', 'metadata', 'embedding', 'id'])\n",
            "\n",
            "  tensor      htype      shape      dtype  compression\n",
            "  -------    -------    -------    -------  ------- \n",
            "   text       text      (10, 1)      str     None   \n",
            " metadata     json      (10, 1)      str     None   \n",
            " embedding  embedding  (10, 1536)  float32   None   \n",
            "    id        text      (10, 1)      str     None   \n",
            "Test question: What is the repository about?\n",
            "==================================================\n",
            "Answer: The repository is about precision and simplicity in information retrieval. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): Give me examples of LlamaIndex index types\n",
            "Your question: Give me examples of LlamaIndex index types\n",
            "==================================================\n",
            "Answer: Summary Index and Vector Store Index are examples of LlamaIndex index types. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): How do I create nodes with LlamaIndex?\n",
            "Your question: How do I create nodes with LlamaIndex?\n",
            "==================================================\n",
            "Answer: To create nodes with LlamaIndex, you can use the `SimpleNodeParser` class. This class is designed to\n",
            "convert the content of documents into structured nodes automatically. First, initialize the parser\n",
            "using the `SimpleNodeParser.from_defaults()` method, specifying the desired chunk size and chunk\n",
            "overlap. Then, you can parse your documents into nodes using the `get_nodes_from_documents()` method\n",
            "of the parser. This will return a list of nodes. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): exit\n",
            "Exiting, thanks for chatting!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the code\n",
        "At first glance, a lot is happening here; let's review it. Below is a step-by-step breakdown:\n",
        "\n",
        "### Initialization and Environment Setup\n",
        "* Import Required Libraries: The script starts by importing all the necessary modules and packages.\n",
        "* Load Environment Variables: Using dotenv, it loads environment variables stored in the .env file. This is where API keys and tokens are stored securely.\n",
        "\n",
        "### Helper Functions\n",
        "* `parse_github_url`(url): This function takes a GitHub URL and extracts the repository owner and name using regular expressions.\n",
        "* `validate_owner_repo`(owner, repo): Validates that both the repository owner and name are present.\n",
        "* `initialize_github_client()`: Initializes the GitHub client using the token fetched from the environment variables.\n",
        "API Key Checks: Before proceeding, the script checks for the presence of the OpenAI API key, GitHub token, and Activeloop token, raising an error if any are missing.\n",
        "* `Initialize GitHub Client`: Calls initialize_github_client() to get a GitHub client instance.\n",
        "* User Input for GitHub URL: Asks the user to input a GitHub repository URL.\n",
        "* URL Parsing and Validation: Parses the URL to get the repository owner and name and validates them.\n",
        "* Data Loading: If the URL is valid, it uses GithubRepositoryReader from llama_index to load the repository data, specifically Python and Markdown files.\n",
        "* Indexing: The loaded data is then indexed using VectorStoreIndex and stored in a DeepLake vector store. This makes the data queryable.\n",
        "* Query Engine Initialization: Initializes a query engine based on the indexed data.\n",
        "* Test Query: Performs a test query to demonstrate the system's operation.\n",
        "* User Queries: Enters a loop where the user can input natural language queries to interact with the indexed GitHub repository. The loop continues until the user types 'exit'.\n",
        "\n",
        "### Execution Entry Point\n",
        "The script uses the standard if __name__ == \"__main__\":"
      ],
      "metadata": {
        "id": "VJ85v4ZB1m7r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SqOoXlSu1bvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90BL-2_I1brH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}